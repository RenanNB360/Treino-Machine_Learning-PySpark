{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandomForest_DecisionTree_College.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNiO0d9JAdblZCyKZK3cvnN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYtLikvQ7hzx","executionInfo":{"status":"ok","timestamp":1644098992302,"user_tz":180,"elapsed":52021,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"a822c7d7-63e8-42f7-e4b7-042d6d48c280"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 51.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=1562ae8a792f31c17e42abbc8e5a8028f5ba4c59770ece1131c2c652270b9d3d\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}],"source":["pip install pyspark"]},{"cell_type":"code","source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler, StringIndexer\n","from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier)\n","from pyspark.ml import pipeline\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator"],"metadata":{"id":"C6BoGlni7tZK","executionInfo":{"status":"ok","timestamp":1644102749367,"user_tz":180,"elapsed":264,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName('cl').getOrCreate()"],"metadata":{"id":"CsGxMF5A8JRH","executionInfo":{"status":"ok","timestamp":1644099110921,"user_tz":180,"elapsed":6935,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = spark.read.csv('College.csv', header=True, inferSchema=True)"],"metadata":{"id":"Q0AHHN2J8Wp0","executionInfo":{"status":"ok","timestamp":1644099336556,"user_tz":180,"elapsed":6432,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTR33X9g9QXm","executionInfo":{"status":"ok","timestamp":1644099347169,"user_tz":180,"elapsed":407,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"c5fe5745-430c-48a1-f2fd-6d05baf4dcec"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n","|              School|Private|Apps|Accept|Enroll|Top10perc|Top25perc|F_Undergrad|P_Undergrad|Outstate|Room_Board|Books|Personal|PhD|Terminal|S_F_Ratio|perc_alumni|Expend|Grad_Rate|\n","+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n","|Abilene Christian...|    Yes|1660|  1232|   721|       23|       52|       2885|        537|    7440|      3300|  450|    2200| 70|      78|     18.1|         12|  7041|       60|\n","|  Adelphi University|    Yes|2186|  1924|   512|       16|       29|       2683|       1227|   12280|      6450|  750|    1500| 29|      30|     12.2|         16| 10527|       56|\n","|      Adrian College|    Yes|1428|  1097|   336|       22|       50|       1036|         99|   11250|      3750|  400|    1165| 53|      66|     12.9|         30|  8735|       54|\n","| Agnes Scott College|    Yes| 417|   349|   137|       60|       89|        510|         63|   12960|      5450|  450|     875| 92|      97|      7.7|         37| 19016|       59|\n","|Alaska Pacific Un...|    Yes| 193|   146|    55|       16|       44|        249|        869|    7560|      4120|  800|    1500| 76|      72|     11.9|          2| 10922|       15|\n","|   Albertson College|    Yes| 587|   479|   158|       38|       62|        678|         41|   13500|      3335|  500|     675| 67|      73|      9.4|         11|  9727|       55|\n","|Albertus Magnus C...|    Yes| 353|   340|   103|       17|       45|        416|        230|   13290|      5720|  500|    1500| 90|      93|     11.5|         26|  8861|       63|\n","|      Albion College|    Yes|1899|  1720|   489|       37|       68|       1594|         32|   13868|      4826|  450|     850| 89|     100|     13.7|         37| 11487|       73|\n","|    Albright College|    Yes|1038|   839|   227|       30|       63|        973|        306|   15595|      4400|  300|     500| 79|      84|     11.3|         23| 11644|       80|\n","|Alderson-Broaddus...|    Yes| 582|   498|   172|       21|       44|        799|         78|   10468|      3380|  660|    1800| 40|      41|     11.5|         15|  8991|       52|\n","|   Alfred University|    Yes|1732|  1425|   472|       37|       75|       1830|        110|   16548|      5406|  500|     600| 82|      88|     11.3|         31| 10932|       73|\n","|   Allegheny College|    Yes|2652|  1900|   484|       44|       77|       1707|         44|   17080|      4440|  400|     600| 73|      91|      9.9|         41| 11711|       76|\n","|Allentown Coll. o...|    Yes|1179|   780|   290|       38|       64|       1130|        638|    9690|      4785|  600|    1000| 60|      84|     13.3|         21|  7940|       74|\n","|        Alma College|    Yes|1267|  1080|   385|       44|       73|       1306|         28|   12572|      4552|  400|     400| 79|      87|     15.3|         32|  9305|       68|\n","|     Alverno College|    Yes| 494|   313|   157|       23|       46|       1317|       1235|    8352|      3640|  650|    2449| 36|      69|     11.1|         26|  8127|       55|\n","|American Internat...|    Yes|1420|  1093|   220|        9|       22|       1018|        287|    8700|      4780|  450|    1400| 78|      84|     14.7|         19|  7355|       69|\n","|     Amherst College|    Yes|4302|   992|   418|       83|       96|       1593|          5|   19760|      5300|  660|    1598| 93|      98|      8.4|         63| 21424|      100|\n","| Anderson University|    Yes|1216|   908|   423|       19|       40|       1819|        281|   10100|      3520|  550|    1100| 48|      61|     12.1|         14|  7994|       59|\n","|  Andrews University|    Yes|1130|   704|   322|       14|       23|       1586|        326|    9996|      3090|  900|    1320| 62|      66|     11.5|         18| 10908|       46|\n","|Angelo State Univ...|     No|3540|  2001|  1016|       24|       54|       4190|       1512|    5130|      3592|  500|    2000| 60|      62|     23.1|          5|  4010|       34|\n","+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFvGwmcz9R1v","executionInfo":{"status":"ok","timestamp":1644099435078,"user_tz":180,"elapsed":272,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"bf40b78d-7c33-42a6-c6bf-ea0c9089af84"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- School: string (nullable = true)\n"," |-- Private: string (nullable = true)\n"," |-- Apps: integer (nullable = true)\n"," |-- Accept: integer (nullable = true)\n"," |-- Enroll: integer (nullable = true)\n"," |-- Top10perc: integer (nullable = true)\n"," |-- Top25perc: integer (nullable = true)\n"," |-- F_Undergrad: integer (nullable = true)\n"," |-- P_Undergrad: integer (nullable = true)\n"," |-- Outstate: integer (nullable = true)\n"," |-- Room_Board: integer (nullable = true)\n"," |-- Books: integer (nullable = true)\n"," |-- Personal: integer (nullable = true)\n"," |-- PhD: integer (nullable = true)\n"," |-- Terminal: integer (nullable = true)\n"," |-- S_F_Ratio: double (nullable = true)\n"," |-- perc_alumni: integer (nullable = true)\n"," |-- Expend: integer (nullable = true)\n"," |-- Grad_Rate: integer (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6UNTOkw9nZ_","executionInfo":{"status":"ok","timestamp":1644099556273,"user_tz":180,"elapsed":386,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"206a1733-a7d4-4b43-e8d8-e55a84eb5687"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(School='Abilene Christian University', Private='Yes', Apps=1660, Accept=1232, Enroll=721, Top10perc=23, Top25perc=52, F_Undergrad=2885, P_Undergrad=537, Outstate=7440, Room_Board=3300, Books=450, Personal=2200, PhD=70, Terminal=78, S_F_Ratio=18.1, perc_alumni=12, Expend=7041, Grad_Rate=60)]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yu2LZJxQ-ASD","executionInfo":{"status":"ok","timestamp":1644099641613,"user_tz":180,"elapsed":281,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"5973e63b-3670-4514-d5d5-85cb4d5fc9db"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['School',\n"," 'Private',\n"," 'Apps',\n"," 'Accept',\n"," 'Enroll',\n"," 'Top10perc',\n"," 'Top25perc',\n"," 'F_Undergrad',\n"," 'P_Undergrad',\n"," 'Outstate',\n"," 'Room_Board',\n"," 'Books',\n"," 'Personal',\n"," 'PhD',\n"," 'Terminal',\n"," 'S_F_Ratio',\n"," 'perc_alumni',\n"," 'Expend',\n"," 'Grad_Rate']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols=['Apps',\n"," 'Accept',\n"," 'Enroll',\n"," 'Top10perc',\n"," 'Top25perc',\n"," 'F_Undergrad',\n"," 'P_Undergrad',\n"," 'Outstate',\n"," 'Room_Board',\n"," 'Books',\n"," 'Personal',\n"," 'PhD',\n"," 'Terminal',\n"," 'S_F_Ratio',\n"," 'perc_alumni',\n"," 'Expend',\n"," 'Grad_Rate'], outputCol='features')"],"metadata":{"id":"7obGugtU-Z1c","executionInfo":{"status":"ok","timestamp":1644099787144,"user_tz":180,"elapsed":4,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["output = assembler.transform(df)"],"metadata":{"id":"_cSuOf5T-9YR","executionInfo":{"status":"ok","timestamp":1644099824330,"user_tz":180,"elapsed":388,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["indexer = StringIndexer(inputCol='Private', outputCol='PrivateIndexer')"],"metadata":{"id":"H8pY3IpM_GXG","executionInfo":{"status":"ok","timestamp":1644099982410,"user_tz":180,"elapsed":249,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["output_fixed = indexer.fit(output).transform(output)"],"metadata":{"id":"XBzbqhhP_tDE","executionInfo":{"status":"ok","timestamp":1644100064898,"user_tz":180,"elapsed":1596,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["output_fixed.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHUavzTEAA3Y","executionInfo":{"status":"ok","timestamp":1644100207703,"user_tz":180,"elapsed":249,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"d12456cb-b519-4360-8ac7-95429d77270f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- School: string (nullable = true)\n"," |-- Private: string (nullable = true)\n"," |-- Apps: integer (nullable = true)\n"," |-- Accept: integer (nullable = true)\n"," |-- Enroll: integer (nullable = true)\n"," |-- Top10perc: integer (nullable = true)\n"," |-- Top25perc: integer (nullable = true)\n"," |-- F_Undergrad: integer (nullable = true)\n"," |-- P_Undergrad: integer (nullable = true)\n"," |-- Outstate: integer (nullable = true)\n"," |-- Room_Board: integer (nullable = true)\n"," |-- Books: integer (nullable = true)\n"," |-- Personal: integer (nullable = true)\n"," |-- PhD: integer (nullable = true)\n"," |-- Terminal: integer (nullable = true)\n"," |-- S_F_Ratio: double (nullable = true)\n"," |-- perc_alumni: integer (nullable = true)\n"," |-- Expend: integer (nullable = true)\n"," |-- Grad_Rate: integer (nullable = true)\n"," |-- features: vector (nullable = true)\n"," |-- PrivateIndexer: double (nullable = false)\n","\n"]}]},{"cell_type":"code","source":["final_df = output_fixed.select('features', 'PrivateIndexer')"],"metadata":{"id":"cpC3D8t4AkCJ","executionInfo":{"status":"ok","timestamp":1644100315162,"user_tz":180,"elapsed":254,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["final_df.show(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScKaZoHzA-SM","executionInfo":{"status":"ok","timestamp":1644100337563,"user_tz":180,"elapsed":276,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"279519b9-2322-467e-87a2-a4b88474307d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------+\n","|            features|PrivateIndexer|\n","+--------------------+--------------+\n","|[1660.0,1232.0,72...|           0.0|\n","|[2186.0,1924.0,51...|           0.0|\n","|[1428.0,1097.0,33...|           0.0|\n","|[417.0,349.0,137....|           0.0|\n","|[193.0,146.0,55.0...|           0.0|\n","+--------------------+--------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["train_df, test_df = final_df.randomSplit([0.7, 0.3])"],"metadata":{"id":"XSCHs-HJA_tW","executionInfo":{"status":"ok","timestamp":1644100412157,"user_tz":180,"elapsed":252,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["dtc = DecisionTreeClassifier(labelCol='PrivateIndexer',featuresCol='features')\n","gbt = GBTClassifier(labelCol='PrivateIndexer',featuresCol='features')\n","rfc = RandomForestClassifier(numTrees=150,labelCol='PrivateIndexer',featuresCol='features')"],"metadata":{"id":"8IIKAqqgBV9y","executionInfo":{"status":"ok","timestamp":1644102613489,"user_tz":180,"elapsed":261,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["dtc_model = dtc.fit(train_df)\n","gbt_model = gbt.fit(train_df)\n","rfc_model = rfc.fit(train_df)"],"metadata":{"id":"7WIiR7dpBZez","executionInfo":{"status":"ok","timestamp":1644102631418,"user_tz":180,"elapsed":16183,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["dtc_preds = dtc_model.transform(test_df)\n","gbt_preds = gbt_model.transform(test_df)\n","rfc_preds = rfc_model.transform(test_df)"],"metadata":{"id":"7VhFCXxDElWI","executionInfo":{"status":"ok","timestamp":1644102634232,"user_tz":180,"elapsed":658,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["binary_eval = BinaryClassificationEvaluator(labelCol='PrivateIndexer')"],"metadata":{"id":"8puZm1WDFYN3","executionInfo":{"status":"ok","timestamp":1644102636300,"user_tz":180,"elapsed":254,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["print(f'DTC: {binary_eval.evaluate(dtc_preds)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"re61u0GuGNCB","executionInfo":{"status":"ok","timestamp":1644102639227,"user_tz":180,"elapsed":651,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"9959cd81-4480-4662-87ed-2c0d375c77e4"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["DTC: 0.9287671232876712\n"]}]},{"cell_type":"code","source":["print(f'RFC: {binary_eval.evaluate(rfc_preds)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDZ0TFWYGwT-","executionInfo":{"status":"ok","timestamp":1644102642457,"user_tz":180,"elapsed":648,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"61585516-a5ed-4967-f064-a2f4361fbc64"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["RFC: 0.9622146118721459\n"]}]},{"cell_type":"code","source":["gbt_preds.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBRe99u5G5jJ","executionInfo":{"status":"ok","timestamp":1644102646517,"user_tz":180,"elapsed":267,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"4bcbcaab-b0ff-4348-a00c-1a94a3364837"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- features: vector (nullable = true)\n"," |-- PrivateIndexer: double (nullable = false)\n"," |-- rawPrediction: vector (nullable = true)\n"," |-- probability: vector (nullable = true)\n"," |-- prediction: double (nullable = false)\n","\n"]}]},{"cell_type":"code","source":["binary_eval2 = BinaryClassificationEvaluator(labelCol='PrivateIndexer', rawPredictionCol='prediction')"],"metadata":{"id":"R28AMqO6H-ve","executionInfo":{"status":"ok","timestamp":1644102649070,"user_tz":180,"elapsed":259,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["print(f'GBT: {binary_eval2.evaluate(gbt_preds)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5wbK9JVIbS2","executionInfo":{"status":"ok","timestamp":1644102650556,"user_tz":180,"elapsed":410,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"36062315-3fd1-4386-b98c-7e808e65317a"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["GBT: 0.8922374429223744\n"]}]},{"cell_type":"code","source":["acc_eval = MulticlassClassificationEvaluator(labelCol='PrivateIndexer',metricName='accuracy')"],"metadata":{"id":"HPOVCq7FIuPs","executionInfo":{"status":"ok","timestamp":1644102900086,"user_tz":180,"elapsed":253,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(f'RFC: {acc_eval.evaluate(rfc_preds)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBrVkcu2Km_R","executionInfo":{"status":"ok","timestamp":1644102974698,"user_tz":180,"elapsed":387,"user":{"displayName":"tutty bittencourt","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04683549783093645127"}},"outputId":"c2038266-9cd2-41e7-81ee-41a3a222631e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["RFC: 0.9174757281553398\n"]}]}]}